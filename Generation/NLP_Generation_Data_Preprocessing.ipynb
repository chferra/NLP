{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# ðŸ“¦ Library installation\n",
    "\n",
    "#may give you truble depending on the permission on your os\n",
    "%pip install numpy transformers datasets accelerate peft --user\n",
    "\n",
    "# âš™ï¸ Library import\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# Datasets management\n",
    "from datasets import load_dataset, Dataset, DatasetDict, load_from_disk\n",
    "\n",
    "# HuggingFace Transformers\n",
    "from transformers import (\n",
    "    T5Tokenizer,\n",
    "    AutoTokenizer, \n",
    "    AutoModelForSeq2SeqLM, \n",
    "    Seq2SeqTrainer, \n",
    "    Seq2SeqTrainingArguments\n",
    ")\n",
    "\n",
    "# PEFT (Parameter Efficient Fine Tuning - for LoRA)\n",
    "from peft import LoraConfig, get_peft_model, prepare_model_for_kbit_training\n",
    "\n",
    "from functools import partial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"\"\n",
    "\n",
    "#Scores\n",
    "train_score_path = \"Scores/xenc_scores_train-stsb-distilroberta-base.npy\"\n",
    "test_score_path = \"Scores/xenc_scores_test-stsb-distilroberta-base.npy\"\n",
    "\n",
    "#Tokenized preprocessed data\n",
    "dataset_path_K3 = \"Processed Data/tokenized_data_K=3\"\n",
    "dataset_path_K2 = \"Processed Data/tokenized_data_K=2\"\n",
    "\n",
    "#Models\n",
    "model_path_t5 = \"Models/t5_small\"\n",
    "model_path_flant5 = \"Models/flan_t5_small\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data load and preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data load"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the documents' score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "document_score_train = np.load(train_score_path, allow_pickle=True)\n",
    "document_score_test = np.load(test_score_path, allow_pickle=True)\n",
    "\n",
    "print(document_score_train.tolist()[0][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Loading the whole dataset\n",
    "dataset = load_dataset(\"FreedomIntelligence/RAG-Instruct\", split=\"train\")\n",
    "\n",
    "# Split 80% train, 20% test\n",
    "train_test_dataset = dataset.train_test_split(test_size=0.2, seed=42)\n",
    "train_dataset = train_test_dataset['train']\n",
    "test_dataset = train_test_dataset['test']\n",
    "\n",
    "print(train_dataset)\n",
    "print(test_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing funcion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def preprocess(example, scores, idx, tokenizer, k=3):\n",
    "    if idx >= len(scores):\n",
    "        return {\n",
    "            \"input_ids\": [],\n",
    "            \"attention_mask\": [],\n",
    "            \"labels\": []\n",
    "        }\n",
    "\n",
    "    question = example['question']\n",
    "    #print(question)\n",
    "    answer = example['answer']\n",
    "    #print(answer)\n",
    "    all_documents = example['documents']\n",
    "    #print(all_documents)\n",
    "\n",
    "    score = scores[idx]\n",
    "    top_k_indices = np.argsort(-score)[:k]\n",
    "    top_k_indices = [int(i) for i in np.array(top_k_indices).flatten()]\n",
    "\n",
    "    selected_docs = [all_documents[i] for i in top_k_indices]\n",
    "\n",
    "    input_text = f\"question: {question} context: {' '.join(selected_docs)}\"\n",
    "    #print(input_text)\n",
    "    target_text = answer\n",
    "\n",
    "    model_inputs = tokenizer(input_text, max_length=1024, truncation=True)\n",
    "    labels = tokenizer(target_text, max_length=256, truncation=True)\n",
    "\n",
    "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
    "    \n",
    "    model_inputs[\"attention_mask\"] = model_inputs.get(\"attention_mask\", [1] * len(model_inputs[\"input_ids\"]))\n",
    "\n",
    "    return model_inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### test preprocessing function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can de-comment the print in the function if you want to debug it\n",
    "print(preprocess(train_dataset[0], document_score_train,0, T5Tokenizer.from_pretrained('t5-base')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Class to apply the preprocess function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PreprocessorWithScores:\n",
    "    def __init__(self, scores, k=3):\n",
    "        self.scores = scores\n",
    "        self.k = k\n",
    "        self.tokenizer = T5Tokenizer.from_pretrained('t5-base')\n",
    "    \n",
    "    def __call__(self, examples, indices):\n",
    "        if isinstance(indices, int):\n",
    "            indices = [indices]\n",
    "\n",
    "        outputs = []\n",
    "        for i, idx in enumerate(indices):\n",
    "            example = {key: examples[key] for key in examples}\n",
    "            output = preprocess(example, self.scores, idx,self.tokenizer, self.k)\n",
    "            outputs.append(output)\n",
    "\n",
    "        return {key: [output[key] for output in outputs] for key in outputs[0]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preprocressing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "K = 2\n",
    "preprocessor_train = PreprocessorWithScores(document_score_train, k=K)\n",
    "preprocessor_test = PreprocessorWithScores(document_score_test, k=K)\n",
    "\n",
    "tokenized_train = train_dataset.map(preprocessor_train, with_indices=True, num_proc=1).filter(lambda example: len(example['input_ids']) > 0)\n",
    "tokenized_test = test_dataset.map(preprocessor_test, with_indices=True, num_proc=1).filter(lambda example: len(example['input_ids']) > 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verify that the tokenization didn't corrupt the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example = tokenized_train[0]\n",
    "input_ids = example['input_ids'][0]\n",
    "labels_ids = example['labels'][0]\n",
    "tokenizer = T5Tokenizer.from_pretrained('t5-base')\n",
    "\n",
    "# Decodifica input e target\n",
    "input_text = tokenizer.decode(input_ids, skip_special_tokens=True)\n",
    "target_text = tokenizer.decode(labels_ids, skip_special_tokens=True)\n",
    "\n",
    "print(\"Input text:\", input_text)\n",
    "print(\"Target text:\", target_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save tokenized datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def save_dataset(dataset, prefix, save_dir):\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    path = os.path.join(save_dir, f\"{prefix}\")\n",
    "    dataset.save_to_disk(path)\n",
    "    print(f\"Dataset salvato in {path}\")\n",
    "\n",
    "if(K == 3):\n",
    "    data_path = dataset_path_K3\n",
    "    \n",
    "if(K == 2):\n",
    "    data_path = dataset_path_K2\n",
    "save_dataset(tokenized_train, 'train', data_path)\n",
    "save_dataset(tokenized_test, 'test', data_path)\n",
    "\n",
    "print(tokenized_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download and save the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def download_and_save_model(model_name, save_dir):\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    model_path = os.path.join(save_dir, model_name.replace(\"/\", \"_\"))\n",
    "    os.makedirs(model_path, exist_ok=True)\n",
    "\n",
    "    print(f\"Downloading {model_name}...\")\n",
    "\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "    model = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n",
    "\n",
    "    print(f\"Saving {model_name} to {model_path}...\")\n",
    "    tokenizer.save_pretrained(model_path)\n",
    "    model.save_pretrained(model_path)\n",
    "\n",
    "    print(f\"{model_name} saved at {model_path}\")\n",
    "\n",
    "# Download one at the time\n",
    "download_and_save_model(\"t5-small\", model_path_t5)\n",
    "download_and_save_model(\"google/flan-t5-small\", model_path_flant5)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 7316993,
     "sourceId": 11659624,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7317384,
     "sourceId": 11660169,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31012,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
