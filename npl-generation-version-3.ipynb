{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":11659624,"sourceType":"datasetVersion","datasetId":7316993},{"sourceId":11660169,"sourceType":"datasetVersion","datasetId":7317384}],"dockerImageVersionId":31012,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Libraries","metadata":{}},{"cell_type":"code","source":"import os\nimport numpy as np\nfrom datasets import load_dataset, Dataset, DatasetDict\nfrom transformers import T5Tokenizer\nfrom tqdm.auto import tqdm\nfrom datasets import load_from_disk","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-05-06T09:02:40.749751Z","iopub.execute_input":"2025-05-06T09:02:40.750211Z","iopub.status.idle":"2025-05-06T09:02:52.870224Z","shell.execute_reply.started":"2025-05-06T09:02:40.750154Z","shell.execute_reply":"2025-05-06T09:02:52.869040Z"}},"outputs":[],"execution_count":1},{"cell_type":"markdown","source":"# Data load and preprocessing","metadata":{}},{"cell_type":"markdown","source":"## Data load","metadata":{}},{"cell_type":"markdown","source":"### Loading the documents' score","metadata":{}},{"cell_type":"code","source":"train_path = \"/kaggle/input/train-document-score/xenc_scores_train-stsb-distilroberta-base.npy\"\ntest_path = \"/kaggle/input/test-score-npy/xenc_scores_test-stsb-distilroberta-base.npy\"\n\ndocument_score_train = np.load(train_path, allow_pickle=True)\ndocument_score_test = np.load(test_path, allow_pickle=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-06T09:02:52.871276Z","iopub.execute_input":"2025-05-06T09:02:52.871762Z","iopub.status.idle":"2025-05-06T09:02:52.956391Z","shell.execute_reply.started":"2025-05-06T09:02:52.871729Z","shell.execute_reply":"2025-05-06T09:02:52.955361Z"}},"outputs":[],"execution_count":2},{"cell_type":"markdown","source":"### Loading the Dataset","metadata":{}},{"cell_type":"code","source":"# Loading the whole dataset\ndataset = load_dataset(\"FreedomIntelligence/RAG-Instruct\", split=\"train\")\n\n# Split 80% train, 20% test\ntrain_test_dataset = dataset.train_test_split(test_size=0.2, seed=42)\ntrain_dataset = train_test_dataset['train']\ntest_dataset = train_test_dataset['test']\n\nprint(train_dataset)\nprint(test_dataset)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-06T09:02:52.958072Z","iopub.execute_input":"2025-05-06T09:02:52.958455Z","iopub.status.idle":"2025-05-06T09:03:09.466023Z","shell.execute_reply.started":"2025-05-06T09:02:52.958426Z","shell.execute_reply":"2025-05-06T09:03:09.465011Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"README.md:   0%|          | 0.00/2.64k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9703deef65194c4e9b6a2f57aed53b23"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"rag_instruct.json:   0%|          | 0.00/296M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"072df2863f514eb28b0058ec9d326bfe"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/40541 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b15538fc40424bc39265894b1a012404"}},"metadata":{}},{"name":"stdout","text":"Dataset({\n    features: ['question', 'answer', 'documents'],\n    num_rows: 32432\n})\nDataset({\n    features: ['question', 'answer', 'documents'],\n    num_rows: 8109\n})\n","output_type":"stream"}],"execution_count":3},{"cell_type":"markdown","source":"## Preprocessing funcion","metadata":{}},{"cell_type":"code","source":"from datasets import Dataset, DatasetDict\nfrom transformers import T5Tokenizer\n\ntokenizer = T5Tokenizer.from_pretrained('t5-base')\n\ndef preprocess(example, scores, idx, k=3):\n    if idx >= len(scores):\n        return {\n            \"input_ids\": [],\n            \"attention_mask\": [],\n            \"labels\": []\n        }\n\n    question = example['question']\n    answer = example['answer']\n    all_documents = example['documents']\n\n    score = scores[idx]\n    top_k_indices = np.argsort(-score)[:k]\n    top_k_indices = [int(i) for i in np.array(top_k_indices).flatten()]\n\n    selected_docs = [all_documents[i] for i in top_k_indices]\n\n    input_text = f\"question: {question} context: {' '.join(selected_docs)}\"\n    target_text = answer\n\n    model_inputs = tokenizer(input_text, max_length=1024, truncation=True)\n    labels = tokenizer(target_text, max_length=256, truncation=True)\n\n    model_inputs[\"labels\"] = labels[\"input_ids\"]\n    \n    model_inputs[\"attention_mask\"] = model_inputs.get(\"attention_mask\", [1] * len(model_inputs[\"input_ids\"]))\n\n    return model_inputs","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-06T09:03:09.466718Z","iopub.execute_input":"2025-05-06T09:03:09.466975Z","iopub.status.idle":"2025-05-06T09:03:13.431396Z","shell.execute_reply.started":"2025-05-06T09:03:09.466957Z","shell.execute_reply":"2025-05-06T09:03:13.430413Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"add38000ed574e388b65d92847808686"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/1.39M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a9b9c6ae0252490d81c24715978db305"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/1.21k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bb7218c57ed84477b06ede21fc0329c6"}},"metadata":{}},{"name":"stderr","text":"You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n","output_type":"stream"}],"execution_count":4},{"cell_type":"markdown","source":"### Class to apply the preprocess function","metadata":{}},{"cell_type":"code","source":"class PreprocessorWithScores:\n    def __init__(self, scores, k=3):\n        self.scores = scores\n        self.k = k\n\n    def __call__(self, examples, indices):\n        if isinstance(indices, int):\n            indices = [indices]\n\n        outputs = []\n        for i, idx in enumerate(indices):\n            example = {key: examples[key][i] for key in examples}\n            output = preprocess(example, self.scores, idx, self.k)\n            outputs.append(output)\n\n        return {key: [output[key] for output in outputs] for key in outputs[0]}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-06T09:03:13.432518Z","iopub.execute_input":"2025-05-06T09:03:13.433075Z","iopub.status.idle":"2025-05-06T09:03:13.440003Z","shell.execute_reply.started":"2025-05-06T09:03:13.433049Z","shell.execute_reply":"2025-05-06T09:03:13.438864Z"}},"outputs":[],"execution_count":5},{"cell_type":"markdown","source":"## Data preprocressing","metadata":{}},{"cell_type":"markdown","source":"### Preprocess dataset","metadata":{}},{"cell_type":"code","source":"K = 2\ndataset_path_K3 = \"/kaggle/working/tokenized_data_K3\"\ndataset_path_K2 = \"/kaggle/working/tokenized_data_K2\"\npreprocessor_train = PreprocessorWithScores(document_score_train, k=K)\npreprocessor_test = PreprocessorWithScores(document_score_test, k=K)\n\ntokenized_train = train_dataset.map(preprocessor_train, with_indices=True, num_proc=4).filter(lambda example: len(example['input_ids']) > 0)\ntokenized_test = test_dataset.map(preprocessor_test, with_indices=True, num_proc=4).filter(lambda example: len(example['input_ids']) > 0)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-06T09:05:18.952382Z","iopub.execute_input":"2025-05-06T09:05:18.952714Z","iopub.status.idle":"2025-05-06T09:05:32.150468Z","shell.execute_reply.started":"2025-05-06T09:05:18.952692Z","shell.execute_reply":"2025-05-06T09:05:32.149048Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Map (num_proc=4):   0%|          | 0/32432 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"881e4181dd92467db1c235ad05c1614b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Filter:   0%|          | 0/32432 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c1e624f0772e423d927dad0e719bbe0a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map (num_proc=4):   0%|          | 0/8109 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ee51befbd3de4664a6f7b4f151a7f058"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Filter:   0%|          | 0/8109 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f5663310faf94810a8d357400c31d8b6"}},"metadata":{}}],"execution_count":10},{"cell_type":"markdown","source":"### Save tokenized datasets in batches","metadata":{}},{"cell_type":"code","source":"def save_dataset(dataset, prefix, save_dir=\"/kaggle/working/tokenized_data\"):\n    os.makedirs(save_dir, exist_ok=True)\n    path = os.path.join(save_dir, f\"{prefix}\")\n    dataset.save_to_disk(path)\n    print(f\"Dataset salvato in {path}\")\n\ndata_path = \"\"\nif(K == 3):\n    data_path = dataset_path_K3\n    \nif(K == 2):\n    data_path = dataset_path_K2\nsave_dataset(tokenized_train, 'train', data_path)\nsave_dataset(tokenized_test, 'test', data_path)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-06T09:05:41.953709Z","iopub.execute_input":"2025-05-06T09:05:41.954021Z","iopub.status.idle":"2025-05-06T09:05:43.147980Z","shell.execute_reply.started":"2025-05-06T09:05:41.953998Z","shell.execute_reply":"2025-05-06T09:05:43.147266Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Saving the dataset (0/1 shards):   0%|          | 0/32432 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"44fe4c271d1146f79b9e29a4f30ed3c6"}},"metadata":{}},{"name":"stdout","text":"Dataset salvato in /kaggle/working/tokenized_data_K2/train\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Saving the dataset (0/1 shards):   0%|          | 0/8109 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f284424ba35b41089295a2291e80ee04"}},"metadata":{}},{"name":"stdout","text":"Dataset salvato in /kaggle/working/tokenized_data_K2/test\n","output_type":"stream"}],"execution_count":11},{"cell_type":"markdown","source":"### Reload batches","metadata":{}},{"cell_type":"code","source":"def load_dataset(prefix, save_dir=\"/kaggle/working/tokenized_data\"):\n    path = os.path.join(save_dir, prefix)\n    dataset = load_from_disk(path)\n    print(f\"Dataset {prefix} caricato da {path}\")\n    return dataset\n\nloaded_train_dataset = load_dataset('train', data_path)\nloaded_test_dataset = load_dataset('test', data_path)\n\nprint(loaded_train_dataset[0].keys())\nprint(len(loaded_train_dataset))\n\nprint(loaded_test_dataset[0].keys())\nprint(len(loaded_test_dataset))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-06T09:20:51.619277Z","iopub.execute_input":"2025-05-06T09:20:51.619628Z","iopub.status.idle":"2025-05-06T09:20:51.644217Z","shell.execute_reply.started":"2025-05-06T09:20:51.619603Z","shell.execute_reply":"2025-05-06T09:20:51.643111Z"}},"outputs":[{"name":"stdout","text":"Dataset train caricato da /kaggle/working/tokenized_data_K2/train\nDataset test caricato da /kaggle/working/tokenized_data_K2/test\ndict_keys(['question', 'answer', 'documents', 'input_ids', 'attention_mask', 'labels'])\n32432\ndict_keys(['question', 'answer', 'documents', 'input_ids', 'attention_mask', 'labels'])\n8109\n","output_type":"stream"}],"execution_count":13},{"cell_type":"markdown","source":"# Training","metadata":{}},{"cell_type":"markdown","source":"## Downlad and save the models","metadata":{}},{"cell_type":"code","source":"from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\nimport os\n\ndef download_and_save_model(model_name, save_dir=\"/kaggle/working/models\"):\n    os.makedirs(save_dir, exist_ok=True)\n    model_path = os.path.join(save_dir, model_name.replace(\"/\", \"_\"))\n    os.makedirs(model_path, exist_ok=True)\n\n    print(f\"Downloading {model_name}...\")\n\n    tokenizer = AutoTokenizer.from_pretrained(model_name)\n    model = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n\n    print(f\"Saving {model_name} to {model_path}...\")\n    tokenizer.save_pretrained(model_path)\n    model.save_pretrained(model_path)\n\n    print(f\"{model_name} saved at {model_path}\")\n\n# Download one at the time\n#download_and_save_model(\"t5-small\")\ndownload_and_save_model(\"google/flan-t5-small\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-06T11:12:46.865940Z","iopub.execute_input":"2025-05-06T11:12:46.866665Z","iopub.status.idle":"2025-05-06T11:12:51.385293Z","shell.execute_reply.started":"2025-05-06T11:12:46.866635Z","shell.execute_reply":"2025-05-06T11:12:51.384042Z"}},"outputs":[{"name":"stdout","text":"Downloading google/flan-t5-small...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/2.54k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"36984f4cc57545a0890dfad86678cdfc"}},"metadata":{}},{"name":"stderr","text":"Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9d5f67dc246548f1875cb85543dddee5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/2.42M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6446d9789ce5471eb14a9a865599dbda"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/2.20k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f769965e0d1140ea83386d869f8831de"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/1.40k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e99170a643e64c3c864ed9889a134894"}},"metadata":{}},{"name":"stderr","text":"Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/308M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1e361f28e6594cba96c6344c63baee04"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/147 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"723f8a8aed5f4fbe981bf74ec990c308"}},"metadata":{}},{"name":"stdout","text":"Saving google/flan-t5-small to /kaggle/working/models/google_flan-t5-small...\ngoogle/flan-t5-small saved at /kaggle/working/models/google_flan-t5-small\n","output_type":"stream"}],"execution_count":15}]}