{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":11659624,"sourceType":"datasetVersion","datasetId":7316993},{"sourceId":11660169,"sourceType":"datasetVersion","datasetId":7317384}],"dockerImageVersionId":31012,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Libraries","metadata":{}},{"cell_type":"code","source":"!pip install hnswlib\n!pip install pyterrier\n!pip install transformers datasets\n\nfrom datasets import load_dataset\nfrom transformers import T5Tokenizer\nimport pandas as pd\nimport random\nfrom datasets import load_dataset\nfrom matplotlib import pyplot as plt\nimport numpy as np\nimport nltk\nfrom nltk.corpus import stopwords\nimport re\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.metrics import silhouette_score\nfrom sklearn.cluster import KMeans\nfrom sklearn.manifold import TSNE\nfrom mpl_toolkits.mplot3d import Axes3D\nfrom sklearn.preprocessing import LabelEncoder\nimport hnswlib\nimport pyterrier as pt\nfrom tqdm import tqdm\nfrom gensim.models.word2vec import Word2Vec","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-05-03T13:20:20.854689Z","iopub.execute_input":"2025-05-03T13:20:20.854918Z","iopub.status.idle":"2025-05-03T13:21:30.528803Z","shell.execute_reply.started":"2025-05-03T13:20:20.854899Z","shell.execute_reply":"2025-05-03T13:21:30.528177Z"}},"outputs":[{"name":"stdout","text":"Collecting hnswlib\n  Downloading hnswlib-0.8.0.tar.gz (36 kB)\n  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\nRequirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from hnswlib) (1.26.4)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy->hnswlib) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy->hnswlib) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy->hnswlib) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy->hnswlib) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy->hnswlib) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy->hnswlib) (2.4.1)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->hnswlib) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->hnswlib) (2022.1.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy->hnswlib) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy->hnswlib) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy->hnswlib) (2024.2.0)\nBuilding wheels for collected packages: hnswlib\n  Building wheel for hnswlib (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n  Created wheel for hnswlib: filename=hnswlib-0.8.0-cp311-cp311-linux_x86_64.whl size=2389209 sha256=a93e5198cf67aec80a3e0a019313dd7ad6e039979ca791e95c5a4f96749990be\n  Stored in directory: /root/.cache/pip/wheels/ea/4e/27/39aebca9958719776e36fada290845a7ef10f053ad70e22ceb\nSuccessfully built hnswlib\nInstalling collected packages: hnswlib\nSuccessfully installed hnswlib-0.8.0\nCollecting pyterrier\n  Downloading pyterrier-0.1.5-py2.py3-none-any.whl.metadata (9.3 kB)\nRequirement already satisfied: Click>=6.0 in /usr/local/lib/python3.11/dist-packages (from pyterrier) (8.1.8)\nRequirement already satisfied: jinja2>=2.10 in /usr/local/lib/python3.11/dist-packages (from pyterrier) (3.1.6)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2>=2.10->pyterrier) (3.0.2)\nDownloading pyterrier-0.1.5-py2.py3-none-any.whl (22 kB)\nInstalling collected packages: pyterrier\nSuccessfully installed pyterrier-0.1.5\nRequirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.51.1)\nRequirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (3.5.0)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\nRequirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.30.2)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\nRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\nRequirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\nRequirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.0)\nRequirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.2)\nRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\nRequirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (19.0.1)\nRequirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.3.8)\nRequirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.3)\nRequirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets) (3.5.0)\nRequirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.70.16)\nCollecting fsspec<=2024.12.0,>=2023.1.0 (from fsspec[http]<=2024.12.0,>=2023.1.0->datasets)\n  Downloading fsspec-2024.12.0-py3-none-any.whl.metadata (11 kB)\nRequirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets) (3.11.16)\nRequirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (2.6.1)\nRequirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.3.2)\nRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (25.3.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.5.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (6.2.0)\nRequirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (0.3.1)\nRequirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.19.0)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (4.13.1)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (2.4.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.1)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.3.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.1.31)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->transformers) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->transformers) (2022.1.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->transformers) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.17->transformers) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.17->transformers) (2024.2.0)\nDownloading fsspec-2024.12.0-py3-none-any.whl (183 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m183.9/183.9 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: fsspec\n  Attempting uninstall: fsspec\n    Found existing installation: fsspec 2025.3.2\n    Uninstalling fsspec-2025.3.2:\n      Successfully uninstalled fsspec-2025.3.2\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ngcsfs 2024.10.0 requires fsspec==2024.10.0, but you have fsspec 2024.12.0 which is incompatible.\ntorch 2.5.1+cu124 requires nvidia-cublas-cu12==12.4.5.8; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cublas-cu12 12.8.4.1 which is incompatible.\ntorch 2.5.1+cu124 requires nvidia-cudnn-cu12==9.1.0.70; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cudnn-cu12 9.3.0.75 which is incompatible.\ntorch 2.5.1+cu124 requires nvidia-cufft-cu12==11.2.1.3; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cufft-cu12 11.3.3.83 which is incompatible.\ntorch 2.5.1+cu124 requires nvidia-curand-cu12==10.3.5.147; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-curand-cu12 10.3.9.90 which is incompatible.\ntorch 2.5.1+cu124 requires nvidia-cusolver-cu12==11.6.1.9; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusolver-cu12 11.7.3.90 which is incompatible.\ntorch 2.5.1+cu124 requires nvidia-cusparse-cu12==12.3.1.170; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusparse-cu12 12.5.8.93 which is incompatible.\ntorch 2.5.1+cu124 requires nvidia-nvjitlink-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-nvjitlink-cu12 12.8.93 which is incompatible.\nbigframes 1.36.0 requires rich<14,>=12.4.4, but you have rich 14.0.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed fsspec-2024.12.0\n","output_type":"stream"}],"execution_count":1},{"cell_type":"markdown","source":"# Data load and preprocessing","metadata":{}},{"cell_type":"markdown","source":"## Data load","metadata":{}},{"cell_type":"markdown","source":"### Loading the documents' score","metadata":{}},{"cell_type":"code","source":"train_path = \"/kaggle/input/train-document-score/xenc_scores_train-stsb-distilroberta-base.npy\"\ntest_path = \"/kaggle/input/test-score-npy/xenc_scores_test-stsb-distilroberta-base.npy\"\n\ndocument_score_train = np.load(train_path)\ndocument_score_test = np.load(test_path)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-03T13:21:30.530042Z","iopub.execute_input":"2025-05-03T13:21:30.530505Z","iopub.status.idle":"2025-05-03T13:21:30.588535Z","shell.execute_reply.started":"2025-05-03T13:21:30.530486Z","shell.execute_reply":"2025-05-03T13:21:30.587839Z"}},"outputs":[],"execution_count":2},{"cell_type":"markdown","source":"### Loading the Dataset","metadata":{}},{"cell_type":"code","source":"# Loading the whole dataset\ndataset = load_dataset(\"FreedomIntelligence/RAG-Instruct\", split=\"train\")\n\n# Split 80% train, 20% test\ntrain_test_dataset = dataset.train_test_split(test_size=0.2, seed=42)\ntrain_dataset = train_test_dataset['train']\ntest_dataset = train_test_dataset['test']\n\nprint(train_dataset)\nprint(test_dataset)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-03T13:21:30.589370Z","iopub.execute_input":"2025-05-03T13:21:30.589621Z","iopub.status.idle":"2025-05-03T13:21:40.422410Z","shell.execute_reply.started":"2025-05-03T13:21:30.589603Z","shell.execute_reply":"2025-05-03T13:21:40.421840Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"README.md:   0%|          | 0.00/2.64k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"daaccf64754748db8436f409c1b744cb"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"rag_instruct.json:   0%|          | 0.00/296M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4ae6e5fa05d2421fa19c70c748f53a14"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/40541 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"65160f77d60b4c049405c68a9dcb3a1e"}},"metadata":{}},{"name":"stdout","text":"Dataset({\n    features: ['question', 'answer', 'documents'],\n    num_rows: 32432\n})\nDataset({\n    features: ['question', 'answer', 'documents'],\n    num_rows: 8109\n})\n","output_type":"stream"}],"execution_count":3},{"cell_type":"markdown","source":"## Preprocessing funcion","metadata":{}},{"cell_type":"code","source":"from datasets import Dataset, DatasetDict\nfrom transformers import T5Tokenizer\n\ntokenizer = T5Tokenizer.from_pretrained('t5-base')\n\ndef preprocess(dataset, scores, k=10):\n    tokenized_dataset = []\n\n    for i in range(len(dataset['question'])): #Iterate along the dataset\n        question = dataset['question'][i]\n        answer = dataset['answer'][i]\n        all_documents = dataset['documents'][i]\n        score = scores[i]\n\n        # Reset documents at any cicle\n        documents = \"\"\n        for j in range(min(k, len(all_documents))):  #iterate long the minimum between k and the lenght of documents\n            documents += (' ' + all_documents[j]) #add the first k documents\n\n        #format the input for the model\n        input_text = f\"question: {question} context:{documents}\"\n        target_text = answer\n\n        #tokenize\n        model_inputs = tokenizer(input_text, max_length=1024, truncation=True)\n        labels = tokenizer(target_text, max_length=256, truncation=True)\n\n        model_inputs[\"labels\"] = labels[\"input_ids\"]\n\n        tokenized_dataset.append(model_inputs)\n\n    # convert the dict list into an HuggingFace Dataset\n    hf_dataset = Dataset.from_list(tokenized_dataset)\n\n    return hf_dataset\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-03T13:21:40.423104Z","iopub.execute_input":"2025-05-03T13:21:40.423372Z","iopub.status.idle":"2025-05-03T13:21:42.374427Z","shell.execute_reply.started":"2025-05-03T13:21:40.423352Z","shell.execute_reply":"2025-05-03T13:21:42.373865Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5dd8d93900254dfca075a6b225dc1e81"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/1.39M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9a720bbaca004c738dad1632497f105c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/1.21k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6bcb065626794f2d901dbbae3dec12fa"}},"metadata":{}},{"name":"stderr","text":"You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n","output_type":"stream"}],"execution_count":4},{"cell_type":"markdown","source":"## Data preprocressing","metadata":{}},{"cell_type":"markdown","source":"### Small example to test the funcion","metadata":{}},{"cell_type":"code","source":"K = 3\ntemp_dataset = train_dataset[0:10]\ntokenized_temp_dataset = preprocess(temp_dataset, document_score_train, K)\n\nprint(tokenized_temp_dataset[0].keys())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-03T13:21:42.375806Z","iopub.execute_input":"2025-05-03T13:21:42.376018Z","iopub.status.idle":"2025-05-03T13:21:42.422137Z","shell.execute_reply.started":"2025-05-03T13:21:42.376002Z","shell.execute_reply":"2025-05-03T13:21:42.421576Z"}},"outputs":[{"name":"stdout","text":"dict_keys(['input_ids', 'attention_mask', 'labels'])\n","output_type":"stream"}],"execution_count":5},{"cell_type":"markdown","source":"### Preprocess dataset","metadata":{}},{"cell_type":"code","source":"K = 3\ntokenized_train_dataset = preprocess(train_dataset, document_score_train, K)\ntokenized_test_dataset = preprocess(test_dataset, document_score_test, K)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-03T13:21:42.422698Z","iopub.execute_input":"2025-05-03T13:21:42.422860Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Print tokenized datasets' keys","metadata":{}},{"cell_type":"code","source":"print(tokenized_temp_dataset[0].keys())","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Save tokenized datasets","metadata":{}},{"cell_type":"code","source":"from datasets import DatasetDict\n\ntokenized_train_save_path = '/kaggle/working/tokenized_train_dataset'\ntokenized_test_save_path = '/kaggle/working/tokenized_test_dataset'\n\ntokenized_train_dataset.save_to_disk(tokenized_train_save_path)\nprint(f\"Dataset salvato in: {tokenized_train_save_path}\")\n\ntokenized_test_dataset.save_to_disk(tokenized_test_save_path)\n\nprint(f\"Dataset salvato in: {tokenized_test_save_path}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}